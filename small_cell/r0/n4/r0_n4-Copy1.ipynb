{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, abspath, join\n",
    "from os import getcwd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS_DIR = getcwd()\n",
    "CLASS_DIR = abspath(join(THIS_DIR, '../../..', 'dsnclasses'))\n",
    "sys.path.append(CLASS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ENOsmall import ENO\n",
    "from CAPMr0 import CAPM\n",
    "from NN4 import Net, DQN\n",
    "from globalvar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 99:  TOKYO, 2011 \n",
      "Best Average Reward \t=    0.168\n",
      "Average Reward \t\t=   -0.828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4232977160>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TRAIN USING data from TOKYO, WAKKANAI and MINAMIDAITO FROM 2005 to 2014\n",
    "dqn = DQN()\n",
    "\n",
    "NO_OF_ITERATIONS = 100\n",
    "best_avg_reward = -1000 #initialize best average reward to very low value\n",
    "PFILENAME = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(8)) #create random filename\n",
    "BFILENAME = \"best\"+PFILENAME + \".pt\" #this file stores the best model\n",
    "TFILENAME = \"terminal\"+PFILENAME + \".pt\" #this file stores the last model\n",
    "\n",
    "avg_reward_rec = [] #record the yearly average rewards over the entire duration of training\n",
    "print('\\nTRAINING IN PROGRESS')\n",
    "\n",
    "for iteration in range(NO_OF_ITERATIONS):\n",
    "    LOCATION = random.choice(['tokyo','wakkanai','minamidaito'])\n",
    "    YEAR = random.choice(np.arange(2005,2015))\n",
    "    capm = CAPM(LOCATION,YEAR,shuffle=True, trainmode=True) #instantiate the CAPM class\n",
    "    capm.eno = ENO(LOCATION,YEAR, shuffle=True, day_balance=True) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "    clear_output()\n",
    "    print('\\nIteration {}:  {}, {} '.format(iteration, LOCATION.upper(), YEAR))\n",
    "    print(\"Best Average Reward \\t= {:8.3f}\".format(best_avg_reward))\n",
    "\n",
    "\n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    record = np.empty(4) #record for battery, henergy, reward and action\n",
    "\n",
    "    transition_rec = np.zeros((capm.eno.TIME_STEPS, N_STATES * 2 + 2)) #record all the transition in one day\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_action(s)\n",
    "        \n",
    "        # present state = [batt, enp, henergy]\n",
    "        record = np.vstack((record, [s[0],s[2],r, a])) # record battery, henergy, reward and action for troubleshooting\n",
    "                                                       # However, we are interested only in the reward\n",
    "\n",
    "        # take action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "\n",
    "        temp_transitions = np.hstack((s, [a, r], s_))\n",
    "        transition_rec[capm.eno.hr-1,:] = temp_transitions\n",
    "\n",
    "        if (day_end):\n",
    "            transition_rec[:,5] = r #broadcast reward to all states\n",
    "            decay_factor = [i for i in (LAMBDA**n for n in reversed(range(0, capm.eno.TIME_STEPS)))]\n",
    "            transition_rec[:,5] = transition_rec[:,5] * decay_factor #decay reward proportionately\n",
    "            dqn.store_day_transition(transition_rec)\n",
    "\n",
    "        if dqn.memory_counter > MEMORY_CAPACITY:\n",
    "            dqn.learn()\n",
    "\n",
    "        if (year_end):\n",
    "#             print(\"End of Year\")\n",
    "            break\n",
    "        \n",
    "        # transition to new state\n",
    "        s = s_\n",
    "\n",
    "    record = np.delete(record, 0, 0) #remove the first row which is garbage\n",
    "    reward_rec = record[:,2]\n",
    "    reward_rec = reward_rec[reward_rec != 0] #remove all zero rewards in the middle of the days\n",
    "    print(\"Average Reward \\t\\t= {:8.3f}\".format(np.mean(reward_rec)))\n",
    "    \n",
    "    # Check if reward beats the High Score and possible save it    \n",
    "    if(best_avg_reward < np.mean(reward_rec)):\n",
    "        best_avg_reward = np.mean(reward_rec)\n",
    "        if (iteration > 20): #save the best models only after 20 iterations\n",
    "            print(\"Saving Model\")\n",
    "            torch.save(dqn.eval_net.state_dict(), BFILENAME)\n",
    "\n",
    "    # Log the average reward in avg_reward_rec\n",
    "    avg_reward_rec = np.append(avg_reward_rec, np.mean(reward_rec))\n",
    "    \n",
    "# End of training\n",
    "# Save the last model\n",
    "torch.save(dqn.eval_net.state_dict(), TFILENAME) \n",
    "\n",
    "# Plot the average reward log\n",
    "plt.plot(avg_reward_rec,'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BFILENAME -> loads the best model\n",
    "#TFILENAME -> loads the last model\n",
    "MODELFILE = BFILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year run test\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'best918V187R.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-caebf9e1b4ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# load the required model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELFILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Used: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMODELFILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/eno/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best918V187R.pt'"
     ]
    }
   ],
   "source": [
    "#Test the trained model for using greedy policy\n",
    "TEST_LOCATION = 'tokyo'\n",
    "TEST_YEAR = 2015\n",
    "print('\\nYear run test')\n",
    "\n",
    "dqn = DQN()\n",
    "capm = CAPM(TEST_LOCATION,TEST_YEAR, shuffle=False, trainmode=False)\n",
    "capm.eno = ENO(TEST_LOCATION,TEST_YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "\n",
    "# load the required model\n",
    "dqn.eval_net.load_state_dict(torch.load(MODELFILE))\n",
    "dqn.eval_net.eval()\n",
    "print('Model Used: ',MODELFILE)\n",
    "\n",
    "s, r, day_end, year_end = capm.reset()\n",
    "yr_test_record = np.empty(4)\n",
    "\n",
    "while True:\n",
    "    a = dqn.choose_greedy_action(s)\n",
    "\n",
    "    #state = [batt, enp, henergy, fcast]\n",
    "    yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "\n",
    "    # take action\n",
    "    s_, r, day_end, year_end = capm.step(a)\n",
    "\n",
    "    if year_end:\n",
    "        print(\"End of Test\")\n",
    "        break\n",
    "       \n",
    "    s = s_\n",
    "\n",
    "yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "\n",
    "#Plot the reward and battery for the entire year run\n",
    "title = TEST_LOCATION.upper() + ',' + str(TEST_YEAR)\n",
    "\n",
    "NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "yr_test_reward_rec = yr_test_record[:,2]\n",
    "yr_test_reward_rec = yr_test_reward_rec[yr_test_reward_rec != 0]\n",
    "print('Average Reward for',title, '=', np.mean(yr_test_reward_rec))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(24,10))\n",
    "fig.suptitle(title, fontsize=15)\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(yr_test_reward_rec)\n",
    "ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "ax1.set_ylim([-3,1])\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(yr_test_record[:,0],'r')\n",
    "ax2.set_title(\"Year Run Battery\")\n",
    "ax2.set_ylim([0,1])\n",
    "plt.sca(ax2)\n",
    "plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the reward and battery for the entire year run on a day by day basis\n",
    "\n",
    "TIME_AXIS = np.arange(0,capm.eno.TIME_STEPS)\n",
    "for DAY in range(0,10):#capm.eno.NO_OF_DAYS):\n",
    "    START = DAY*24\n",
    "    END = START+24\n",
    "    \n",
    "    daytitle = title + ' - DAY ' + str(DAY)\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    st = fig.suptitle(daytitle)\n",
    "\n",
    "    ax2 = fig.add_subplot(121)\n",
    "    ax2.plot(yr_test_record[START:END,1],'g')\n",
    "    ax2.set_title(\"HARVESTED ENERGY\")\n",
    "    plt.xlabel(\"Hour\")\n",
    "    ax2.set_ylim([0,1])\n",
    "\n",
    "    #plot battery for year run\n",
    "    ax1 = fig.add_subplot(122)\n",
    "    ax1.plot(TIME_AXIS,yr_test_record[START:END,0],'r') \n",
    "#     ax1.plot(TIME_AXIS, np.ones(capm.eno.TIME_STEPS)*capm.BOPT/capm.BMAX,'r--')\n",
    "    ax1.plot(TIME_AXIS, np.ones(capm.eno.TIME_STEPS)*yr_test_record[START,0],'r--')\n",
    "    ax1.text(0.1, 0.2, \"BINIT = %.2f\\n\" %(yr_test_record[START,0]),fontsize=11, ha='left')\n",
    "    ax1.text(0.1, 0.4, \"TENP = %.2f\\n\" %(capm.BOPT/capm.BMAX-yr_test_record[END,0]),fontsize=11, ha='left')\n",
    "    ax1.text(0.1, 0.3, \"BMEAN = %.2f\\n\" %(np.mean(yr_test_record[START:END,0])),fontsize=11, ha='left')\n",
    "\n",
    "\n",
    "\n",
    "    ax1.set_title(\"YEAR RUN TEST\")\n",
    "    if END < (capm.eno.NO_OF_DAYS*capm.eno.TIME_STEPS):\n",
    "        ax1.text(0.1, 0, \"REWARD = %.2f\\n\" %(yr_test_record[END,2]),fontsize=13, ha='left')\n",
    "    plt.xlabel(\"Hour\")\n",
    "    ax1.set_ylabel('Battery', color='r',fontsize=12)\n",
    "    ax1.set_ylim([0,1])\n",
    "\n",
    "    #plot actions for year run\n",
    "    ax1a = ax1.twinx()\n",
    "    ax1a.plot(yr_test_record[START:END,3])\n",
    "    ax1a.set_ylim([0,N_ACTIONS])\n",
    "    ax1a.set_ylabel('Duty Cycle', color='b',fontsize=12)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    st.set_y(0.95)\n",
    "    fig.subplots_adjust(top=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
